<!--  The original nerual talk2 dispaly webpage are offelined through this comment
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>neuraltalk2 results visualization</title>
    <script src="jquery-1.8.3.min.js"></script>
    <style>
    body {
      background: #000;
      margin: 0;
      font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
      font-weight: 200;
    }
    .result {
      background: no-repeat center/contain #141414;
      color: #fff;
      height: 18vw;
      position: relative;
      width: 32vw;
      display: inline-block;
    }
    .result:nth-child(2n+1) {
      background-color: #181818;
    }
    .result p {
      background: rgba(0, 0, 0, .5);
      bottom: 0;
      box-sizing: border-box;
      left: 0;
      margin: 0;
      padding: 5px;
      position: absolute;
      text-shadow: 0 1px 1px #000;
      width: 100%;
    }
    #results {
      margin: 1.5vw auto;
      width: 96vw;
    }
    </style>
  </head>
  <body>
    <div id="results"></div>
    <script>
    function loadVisible() {
      var top = $(document).scrollTop(), bottom = top + $(window).height();
      var results = $('#results > div')
      for (var i = 0; i < results.length; i++) {
        var div = results.eq(i);
        var y1 = div.position().top, y2 = y1 + div.height();
        if (y1 > bottom || y2 < top) {
          div.css('background-image', '');
          continue;
        }
        div.css('background-image', 'url(' + div.data('image') + ')');
      }
    }
    $(window).scroll(loadVisible);
    $.getJSON('vis.json?t=' + +new Date, function (data) {
      $('#results').html('');
      for (var i = 0; i < data.length; i++) {
        var path = 'imgs/img' + (i + 1) + '.jpg';
        $('<div class="result">')
          .data('image', path)
          .append($('<p>').text(data[i].caption))
          .appendTo('#results');
      }
      loadVisible();
    });
    </script>
  </body>
</html>
-->
<!-- here starts the contents for CIVL1000 assigment#1 16.10.2018-->


<!-- here starts the contents for IJCAI2019 FPVLS  16.3.2019-->  
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>FPVLS</title>
    <script src="jquery-1.8.3.min.js"></script>
<style>
#header {
    background-color:#F2F1D7;
    color:Black;
    text-align:center;
    padding:5px;
}
#nav {
    line-height:30px;
    background-color:#eeeeee;
    height:13500px;
    width:200px;
    float:left;
    padding:5px;        
}
#section {
    width:1000px;
    float:left;
    padding:10px;    
}
#footer {
    background-color:black;
    color:white;
    clear:both;
    text-align:center;
   padding:5px;    
}
</style>
</head>

<body>

<div id="header">
<font size="7" face="Times"><center>FPVLS: Personal Privacy Protection Using Face Pixelation in Video Live Streaming</font><br><br>
	<font size="4" face="Times" color= "#5e083c"><center><I>University ML Camp 2019 Jeju</I>&nbsp&nbsp&nbsp&nbsp<img src="/imgs/JDC.jpg" align="middle" width="5%" height="5%"/><img src="/imgs/JEJU.jpeg" align="middle" width="5%" height="5%"/><img src="/imgs/NHN.png" align="middle" width="5%" height="5%"/></font><br>
</div>

<div id="nav"><h3>
  <a href="#"><p style="font-family:verdana;font-size:80%;color:green"><I>#1:Brief Introduction</I></p><br></a>
  <a href="#"><p style="font-family:verdana;font-size:80%;color:green"><I>#2:Working Pipeline</I></p><br></a>
  <a href="#"><p style="font-family:verdana;font-size:80%;color:green"><I>#3:More Video Pixelation Results on High-resolution Multi-people (HS) Scenario</I></p><br></a>
  <a href="#"><p style="font-family:verdana;font-size:80%;color:green"><I>#4:More Video Pixelation Results on Low-resolution Few-people (LN) Scenario</I></p><br></a>
  <a href="#"><p style="font-family:verdana;font-size:80%;color:green"><I>#5:Brief Conclusion</I></p><br></a>
</h3>
</div>	
	
<div id="section">
  <h2><center><I>Brief Introdcution</I></h2>
    <h3><align="left"><font face=Times color=gray>
As the prevailing of video live streaming, establishing
online pixelation, or at least online face pixelation mechanism, is
an urgency. In this paper, we develop a new method called Face
Pixelation in Video Live Streaming (FPVLS) to generate automatic personal privacy filtering during unconstrained streaming
activities. Simply applying multi-face trackers will encounter
the problem in computing efficiency, target drifting, and overpixelation due to the inherent feature of live video streaming.
Therefore, for fast and accurate pixelation of irrelevant people’s
faces, FPVLS is organized in a frame-to-video structure with
two core stages. On individual frames, our framework utilizes
the fast and cost-effective merits of image-based face detection
and embedding networks to yield face vectors. We propose a
Positioned Incremental Affinity Propagation (PIAP) clustering
algorithm to associate the same person’s faces across frames
according to face vectors and corresponding positions. PIAP
also extends the classic affinity propagation into an incremental
way for the efficient generation of the raw face trajectories.
Such frame-wise accumulated raw trajectories are likely to be
intermittent and unreliable on video level. Hence, we further
introduce a trajectory refinement stage that merges a proposal
network for loosed face detection with the two-sample test based
on the Empirical Likelihood Ratio (ELR) statistic to compensate
the deep network insufficiency and refine the raw trajectories
seamlessly. The shallow proposal network and ELR will not
trigger the computation burden. A Gaussian filter is laid on
the refined trajectories for final pixelation.
</align="left"></font></h3>
<br><br><div id="section">
<h2><center><I>Graph of Conceptual Working Pipeline</I></h2>
  <p><img src="/imgs/Figure1.png"  alt="Conceptual Working Pipeline" /></p>

<br><br><div id="section">
<h2><center><I>Toy example of PIAP Clustering</I></h2>
	<br><h3><align="left"><font face=Times color=gray>
		A toy example of how PIAP Clustering works is presented. (a)-(i) are corresponding to left-to-right and then top-to-bottom order of pictures in the toy example.
	       Traditional AP clustering is implemented on the first batch of objects, it converges in (a), and the clustering result is shown in (b). New objects arrive in (c), and aggregated affinity is recomputed in (d). Message-passing continues in (e) and (h), and reconverges in (i). The final clustering result is shown in (i).
		</align="left"></font></h3>
  <p><img src="/imgs/Annotation.png" width="100%" height="100%" alt="PIAP Example" /></p>
	
	
<br><br><div id="section">
<h2><center><I>The Structure of Proposal Net(Compensate Detection through Shallow CNN)</I></h2>
	<br><h3><align="left"><font face=Times color=gray>
	To fix gaps accumulated by false negatives in a trajectory, we build a proposal net structured as below. The proposal net resizes frames as MTCNN does, and proposes suspicious face areas in such gap frames.
	</align="left"></font></h3>
  <p><img src="/imgs/2 (1).png" width="65%" height="65%" hspace="100" vspace="30" alt="Proposal Net" /></p>

	<br><br><div id="section">
<h2><center><I>Two-sample test based on ELR (compensate the detection lost)</I></h2>
	<br><h3><align="left"><font face=Times color=gray>
	Relationship of z (solid line) and z' (orange dash lines). Orange dots are the suspicious faces proposed by the proposal network. Red areas on z are the breaks recovred by
interpolation.
	</align="left"></font></h3>
  <p><img src="/imgs/relate.png" width="65%" height="65%" hspace="100" vspace="30" alt="Proposal Net" /></p>
	

<br><br><div id="section">
  <br><br>
	<h2><center><I>Video Test Data Results(Naive Cases)</I></h2>
	<body>
		<video controls="controls">
        	<source src="short demo.mp4" type="video/mp4">
        	Your browser does not support the HTML5 Video element.
    		</video>
	</body>
		<body>
		<video controls="controls">
        	<source src="videotest1.mp4" type="video/mp4">
        	Your browser does not support the HTML5 Video element.
    		</video>
	</body>
	<body>
		<video controls="controls">
        	<source src="ouput_test6_revised.mp4" type="video/mp4">
        	Your browser does not support the HTML5 Video element.
       		</video>
	</body>	
		
		
		
		

		
<br><br><div id="section">
  <br><br>
	<h2><center><I>Video Test Data Results(sophisticated Cases)</I></h2>
	<h3><align="left"><font face=Times color=gray>
        Youtude Studio offline tools failed to produce any mosaics in first few tens of seconds. Then, after some recalibration, Youtube Studio works under heavy drifting problems.
        </align="left"></font></h3>

	<body>
		<iframe width="780" height="470" src="https://www.youtube.com/embed/2YW0fgFH0YQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

		
<!--
		
		<iframe width="420" height="315"
        	src="https://youtu.be/2YW0fgFH0YQ">
		</iframe>
-->
	</body>
	
	<h3><align="left"><font face=Times color=gray>
        Our FPVLS results with PIPA clustering algorithm, and the compensation algorithm is not yet applied in following demo.
        </align="left"></font></h3>
       <body>
		<iframe width="780" height="470"
        	<iframe src="//player.bilibili.com/player.html?aid=34105897&cid=59738621&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
   		</iframe>
	</body>	  
		
		
		
		
		
		
	<h3><align="left"><font face=Times color=gray>
        Our FPVLS results with the compensation algorithm.
        </align="left"></font></h3>
	<body>
	<iframe width="780" height="470" src="//player.bilibili.com/player.html?aid=35644211&cid=62513277&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
	</body>	 

		
	<h3><align="left"><font face=Times color=red>
        Some further extension and promotion of FPVLS is on paper <a href="https://dl.acm.org/doi/10.1145/3394171.3413972" title="Privacy-sensitive Objects Pixelation for Live Video Streaming">Privacy-sensitive Objects Pixelation for Live Video Streaming</a>. We proposed a more sound method that works for any privacy-sensitive objects in video live streaming. This work is published in conference of ACM Multimedia 2020. Here is a short video to give you hint of how the pixelation algorithm behaves.
        </align="left"></font></h3>                                 
	<body>
	<iframe src="//player.bilibili.com/player.html?aid=372108715&bvid=BV1JZ4y1N74Z&cid=233490956&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
	</body>	 
	
	
	
	
	
	
	
	
	
	
	
	
	
<br><br><div id="section">
  <h2><center><I>Pixelation Results Analysis#1</I></h2>
    <h4><align="left"><font face=arial color=gray>
      We demonstrate the pixelation results of FPVLS vs. Youtube Studio offered offline face blur tool on 1080p high resolution (H) multi-people (S) scenario in this section. A thumbnail is used to show the results of pixelation in sequential order from left to right. Since the paper-sized thumbnail cannot present the details, we also show the origin pictures under the thumbnail one after one. The upper row of the thumbnail is produced offline by Youtube Studio; FPVLS generates the lower row in real-time. This test presents the FPVLS's ability of raw trajectories refinement. The live-streaming happened in a crowded street with a noisy and complex backgournd. Except the main streamer James Xiao, all other people including the dancers are set to be blurred. With unpredictable camera movements, tracking algorithms cannot handle the drifting and tracking loss problem due to the failed linkage of tracklets. However, FPVLS can still place mosaics on irrelevant people's faces precisely through compensating detections and empirical likelihood ratio test.
      <br></align="left"></font></h4>
      <p><center><font size="5" face="arial" color="red">The Thumbnail of Pixelation Results#1<br></center></font></p>
        <p><img src="/imgs/R2.png"  alt="thumbnail" /></p>
      <p><center><font size="5" face="arial" color="red">Original Pictures of Pixelation Results#1<br></center></font></p>
      <p></p>
      <table border="5"><tr>
        <th><h3><font color=blue>Youtube Studio Pixelation Results</font></h3></th>
        <th><h3><font color=blue>FPVLS Pixelation Results</font></h3></th>
        </tr>
        <tr>
        <td><img src="/imgs/309.png" height="681" width="666" ></td>
        <td><img src="/imgs/409.png" height="681" width="666" ></td>
        </tr>
        <tr>
        <td><img src="/imgs/310.png" height="681" width="666" ></td>
        <td><img src="/imgs/410.png" height="681" width="666" ></td>
        </tr>
        <tr>
        <td><img src="/imgs/311.png" height="681" width="666" ></td>
        <td><img src="/imgs/411.png" height="681" width="666" ></td>
        </tr>
        <tr>
        <td><img src="/imgs/312.png" height="681" width="666" ></td>
        <td><img src="/imgs/412.png" height="681" width="666" ></td>
        </tr></table>



<!--
        <p><img src="/imgs/309.png"  alt="Youtube Studio Offline Face Blur Result" /><img src="/imgs/409.png"  alt="FPVLS Face Blur Result" /> </p>
        <p><img src="/imgs/310.png"  alt="Youtube Studio Offline Face Blur Result" /></p>
        <p><img src="/imgs/311.png"  alt="Youtube Studio Offline Face Blur Result" /></p>
        <p><img src="/imgs/312.png"  alt="Youtube Studio Offline Face Blur Result" /></p>
      <h3><center>FPVLS Pixelation Results#1</center></h3>
        <p></p>
        <p><img src="/imgs/409.png"  alt="FPVLS Face Blur Result" /></p>
        <p><img src="/imgs/410.png"  alt="FPVLS Face Blur Result" /></p>
        <p><img src="/imgs/411.png"  alt="FPVLS Face Blur Result" /></p>
        <p><img src="/imgs/412.png"  alt="FPVLS Face Blur Result" /></p>
-->

<br><br><div id="section">
  <h2><center><I>Pixelation Results Analysis#2</I></h2>
    <h4><align="left"><font face=arial color=gray>
      Another pixelation result of FPVLS vs. Youtube Studio on low resolution (480p) (L) few-people (N) scenario is shown in this section. A thumbnail is used to display the results of pixelation in live-streaming from left to right. Since the paper-sized thumbnail cannot present the details, we also show the origin pictures under the thumbnail one after one. The upper row of the thumbnail is produced offline by Youtube Studio. FPVLS generates the lower row in real-time. This test focus on the typical over-pixelation problem that cannot be handled by the current face tracking algorithms. James Xiao is playing the piano while his friend is watching. His friend's face is set to be blurred for privacy protection.When two or more faces are overlapped with each other, we don't want to pixelate the occluded faces anymore since they are invisible to the audience. However, for tracking algorithms, they insist on predicting the movement of such partial/fully occluded faces and retain their tracklet. These algorithms will produce many annoying and odd mosaics during streaming.
      <br></align="left"></font></h4>
      <p><center><font size="5" face="arial" color="red">The Thumbnail of Pixelation Results#2<br></center></font></p>
        <p><img src="/imgs/R1.png"  alt="thumbnail" /></p>
      <p><center><font size="5" face="arial" color="red">Original Pictures of Pixelation Results#2<br></center></font></p>
      <p></p>
      <table border="5"><tr>
        <th><h3><font color=blue>Youtube Studio Pixelation Results</font></h3></th>
        <th><h3><font color=blue>FPVLS Pixelation Results</font></h3></th>
        </tr>
        <tr>
        <td><img src="/imgs/116.png" height="570" width="400" ></td>
        <td><img src="/imgs/117.png" height="570" width="400" ></td>
        </tr>
        <tr>
        <td><img src="/imgs/111.png" height="570" width="400" ></td>
        <td><img src="/imgs/112.png" height="570" width="400" ></td>
        </tr>
        <tr>
        <td><img src="/imgs/114.png" height="570" width="400" ></td>
        <td><img src="/imgs/113.png" height="570" width="400" ></td>
        </tr>
        <tr>
        <td><img src="/imgs/126.png" height="570" width="400" ></td>
        <td><img src="/imgs/123.png" height="570" width="400" ></td>
        </tr></table>


	  
	  
	  
	  

<br><br><div id="section">
  <br><br>
  <h2><center><I>Brief Conclusion</I></h2>
    <h3><align="left"><font face=Times color=gray>
      According to our knowledge, we are the first to address the face pixelation problem in live video streaming by building the proposed FPVLS. FPVLS is already surpassing offline tool offered by YouTube and Microsoft and becomes applicable in real life scenarios. FPVLS can achieve high accuracy and real-time performances on the dataset we collected. We will extend FPVLS to behave on other privacy sensitive objects in the future.
      </align="left"></font></h3>
    
    
    

    
    
    
<!--

        <p><img src="/imgs/116.png"  alt="Youtube Studio Offline Face Blur Result" /></p>
        <p><img src="/imgs/111.png"  alt="Youtube Studio Offline Face Blur Result" /></p>
        <p><img src="/imgs/114.png"  alt="Youtube Studio Offline Face Blur Result" /></p>
        <p><img src="/imgs/126.png"  alt="Youtube Studio Offline Face Blur Result" /></p>
      <h3><center>FPVLS Pixelation Results#2</center></h3>
      <p></p>
        <p><img src="/imgs/117.png"  alt="FPVLS Face Blur Result" /></p>
        <p><img src="/imgs/112.png"  alt="FPVLS Face Blur Result" /></p>
        <p><img src="/imgs/113.png"  alt="FPVLS Face Blur Result" /></p>
        <p><img src="/imgs/123.png"  alt="FPVLS Face Blur Result" /></p>

-->





<!--
<h5><align="left"> <font color=red> Your code should something like the following: </font></h5>  
<p>/******************************************************************************</p>
<p><center>  <font color=gray>                       CIVL1000 Assignment#1                          </font>       </p>
<p><center>  <font color=gray>                           Question#1                                  </font>      </p> 
<p><center>  <font color=gray>                                 By: DB123456 Knight, Zhou Jizhe       </font>      </p>
<p><center>  <font color=gray>                                                     16.10.2018         </font>    </p>  
<p>*******************************************************************************/</p>  
<p align="left">
#include &lt;iostream&gt;
</p>
<p align="left">
using namespace std;
</p>
  <p align="left">  
 <font color=gray>//main function for Question #1</font>
  </p>
  
  
<p align="left">  
int main() 
  
</p>
<p align="left">  
{
</p>
  <p align="left">
    <font color=gray>  &nbsp; &nbsp; &nbsp; &nbsp; //meaningful variable name "indent" to show indentation</font>
   </p> 
    <p align="left">
    &nbsp; &nbsp; &nbsp; &nbsp;int indent=1;
  </p>
    <p align="left">
    <font color=gray>  &nbsp; &nbsp; &nbsp; &nbsp; //proper indentation initialized here</font>
    </p>
  <p align="left">
    &nbsp; &nbsp; &nbsp; &nbsp;if(indent)
    </p>

   
  <p align="left">
  <font color=gray>  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // call cout function to echo "Hello World" on screen </font>
</p>
  <p align="left">
    &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cout<<"Hello World";
</p>
  <p align="left">
   &nbsp; &nbsp; &nbsp; &nbsp; return 0;
    </p>
<p align="left">
  }  
  </p>
  
 <br> 
 </br> 
 <br> 
 </br> 
  
  
  
  
  
  


  
<div id="section">
<h2><center>Question #2</h2>
<h3><center>DB123456x02.cpp</h3>
<h5 align="left"> <font color=red> Your code should something like the following: </font></h5>   
<p>/******************************************************************************</p>
<p><center>  <font color=gray>                       CIVL1000 Assignment#1                          </font>       </p>
<p><center>  <font color=gray>                           Question#2                                 </font>      </p> 
<p><center>  <font color=gray>                                 By: DB123456 Knight, Zhou Jizhe       </font>      </p>
<p><center>  <font color=gray>                                                     16.10.2018         </font>    </p>  
<p>*******************************************************************************/</p>  
<p align="left">
#include &lt;iostream&gt;
</p>
<p align="left">
using namespace std;
</p>
  <p align="left">  
 <font color=gray>//main function for Question #2</font>
  </p>
  
  
<p align="left">  
int main() 
  
</p>
<p align="left">  
{
</p>
  
  
  <p align="left">
  <font color=gray>  &nbsp; &nbsp; &nbsp; &nbsp; // call cout function to echo "Hello World" on screen </font>
</p>
  <p align="left">
    &nbsp; &nbsp; &nbsp; &nbsp; cout<<"Hello World";
</p>
  <p align="left">
   &nbsp; &nbsp; &nbsp; &nbsp; return 0;
    </p>
<p align="left">
  }  
  </p>
  
 
  
<div id="section">
<h5> 
<p align="left"> <font color=red> A online C++ Complier is linked in the left bar in case the lab is unavailable to you. </font></p>
<p align="left"> <font color=red> Directly write your code within the web and every other things are similar with those in VC++ </font></p>
</h5>  
  
  
-->
<div id="footer">
<font color=red>Full opensource data is underconstruction, we will release full code A.S.A.P</font>
</div>

</body>
</html>
